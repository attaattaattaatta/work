MGR_PATH="/usr/local/mgr5" ;
MGR_BIN="$MGR_PATH/sbin/mgrctl" ; 
MGR_CTL="$MGR_PATH/sbin/mgrctl -m ispmgr" ; 
MGR_MAIN_CONF_FILE="$MGR_PATH/etc/ispmgr.conf" ; 

GCV="\033[0;92m" ; 
LRV="\033[1;91m" ; 
YCV="\033[01;33m" ; 
NCV="\033[0m" ; 

alias ispmgrctl="$MGR_CTL" ; 

function fix7 { sed -i "s/^mirrorlist=/#mirrorlist=/g" /etc/yum.repos.d/CentOS-*; sed -i "s|#baseurl=http://mirror.centos.org|baseurl=http://vault.centos.org|g" /etc/yum.repos.d/CentOS-*; yum --enablerepo=updates clean metadata > /dev/null 2>&1; \rm -f /etc/yum.repos.d/epel-testing.repo /etc/yum.repos.d/epel.repo > /dev/null 2>&1; } ;

function net1 { if command -v netstat &> /dev/null; then netstat -nt | awk "{print \$6}" | sort | uniq -c | sort -n -k 1 -r | head -n -1; else ss -tulpan "! dst 0.0.0.0 and ! dst [::1]" | awk " \$6 ~ /^[0-9]/ {print \$6}" | cut -d: -f1 | sort | uniq -c | sort -n | tail -n 6; ss -nta | awk "{print \$1}" | sort | uniq -c | sort -n -k 1 -r | head -n -1; fi; } ;

function net2 { while true; do lsof -i -n -P | grep -vE "LISTEN|rpcbind|ESTABLISHED|named|chronyd|memcached|ntpd|core|COMMAND"; sleep 1s; done; } ;

function net3 { if command -v netstat &> /dev/null; then netstat -ntu | awk " \$5 ~ /^[0-9]/ {print \$5}" | cut -d: -f1 | sort | uniq -c | sort -n | tail -n 300; else ss -tulpan "! dst 0.0.0.0 and ! dst [::1]" | awk " \$6 ~ /^[0-9]/ {print \$6}" | cut -d: -f1 | sort | uniq -c | sort -n | tail -n 300; fi; } ;

function net4 { watch -n 2 "ss -s && echo &&  cat /proc/net/sockstat && echo && netstat -nt | awk \"{print \$6}\" | sort | uniq -c | sort -n -k 1 -r | head -n -1"; } ;

function tuner { mysql -V; grep -RiE "socket\s+?=" /etc/my*; mysql -e ' show variables where Variable_Name in ("innodb_lru_scan_depth", "optimizer_search_depth", "myisam_recover", "myisam_recover", "max_connect_errors", "default_storage_engine", "transaction_isolation", "tx_isolation", "slave_net_timeout", "innodb_use_sys_malloc", "sql_mode", "collation_server", "init_connect", "character_set_server", "query_cache_size", "query_cache_limit", "query_cache_type", "expire_logs_days", "max_binlog_size", "thread_stack", "thread_pool_size", "open_files_limit", "table_cache", "table_definition_cache", "table_open_cache", "key_buffer_size", "sort_buffer_size", "join_buffer_size", "innodb_force_recovery ", "innodb_buffer_pool_size", "innodb_io_capacity_max", "innodb_io_capacity", "innodb_strict_mode", "innodb_max_dirty_pages_pct", "innodb_thread_concurrency", "innodb_print_all_deadlocks", "innodb_buffer_pool_instances", "innodb_log_file_size", "innodb_log_buffer_size", "innodb_file_format", "innodb_flush_log_at_trx_commit", "innodb_flush_method", "innodb_file_per_table", "wait_timeout", "interactive_timeout", "back_log", "threads_connected", "thread_concurrency", "thread_cache_size", "max_connections", "max_heap_table_size", "tmp_table_size", "max_allowed_packet", "symbolic_links", "local_infile", "bind_address", "basedir", "datadir", "tmpdir", "log_warnings", "long_query_time", "slow_query_log", "slow_query_log_file", "log_error", "pid_file", "socket", "binlog_expire_logs_seconds","innodb_page_cleaners")'; mysql -e "SELECT @@character_set_database, @@collation_database;"; perl <($wgtvr  "https://raw.github.com/major/MySQLTuner-perl/master/mysqltuner.pl") --buffers --skippassword --user root --host localhost; } ;

function nr { nginx -T | grep root $1 || grep -RiIn root /etc/nginx/* $1 ; } ;

function nacc { nginx -T | grep acc $1 || grep -RiIn acc /etc/nginx/* $1 ; } ;

function nerr { nginx -T | grep err $1 || grep -RiIn err /etc/nginx/* $1 ; } ;

function nssl { nginx -T | grep ssl_ $1 || grep -RiIn ssl_ /etc/nginx/* $1 ; } ;

function nconf { nginx -T | grep conf $1 || grep -RiIn conf /etc/nginx/* $1 ; } ;

function nserv { nginx -T | grep server_name $1 || grep -RiIn server_name /etc/nginx/* $1 ; } ;

function ninc { nginx -T | grep include $1 || grep -RiIn include /etc/nginx/* $1 ; } ;

alias rsynca='rsync -azx --no-i-r --info=progress2' ;

alias rsynch='rsync -aHzx --no-i-r --info=progress2' ;

alias grepn='grep -RiIn' ;

alias grepl='grep -RiIl' ;

function sysfailed { systemctl list-units --failed; } ;

alias ll='ls -la' ;

alias la='ls -la' ;

alias du='du -sch' ;

function cl { cat /etc/crontab; for user in $(getent passwd | cut -f1 -d: ); do echo $user && echo && crontab -u $user -l && echo; done; systemctl list-timers; } ;

alias lat='ls -latrh' ;

alias lah='ls -latrh' ;

function sysfail { systemctl list-units --state=failed; } ;

alias journalctl='journalctl -l --no-pager -n 200 -u'; 

function exit1 {  kill -9 $$; } ;

function exit2 {  history -c; > /root/.bash_history; kill -9 $$; } ;

function tw {  bash <($wgtvr https://bit.ly/3nelivO) tweak; } ;

function mylog { grep -ri "log.error" /etc/my*; } ;

function myl { DBSZ="SELECT table_schema AS \`DB Name\`, ROUND(SUM(data_length + index_length) / 1024 / 1024, 1) AS \`DB Size(MB)\` FROM information_schema.tables GROUP BY table_schema ORDER BY \`DB Size(MB)\` ASC;"; if which docker &> /dev/null; then DOCKERDB="docker ps --format {{.Names}}"; for cont in $($DOCKERDB | grep -iE "percona|mysql|mariadb"); do echo; printf "DBs in container ${cont}:\n\n"; \docker exec -it $cont mysql -e "$DBSZ" 2>/dev/null; done; fi; echo; printf "Native mysql:\n\n"; mysql -e "$DBSZ" 2>/dev/null; } ;

function myb { MYSQL_USERS="mysql -e \"select concat('show create user ','\'',user,'\'@\'',host,'\'',';') from mysql.user\""; BKPMSQLD="/root/support/mysql.backup.$(date "+%d-%b-%Y-%H-%M-%Z")"; \mkdir -p "$BKPMSQLD" &> /dev/null;RNDFILE2="/tmp/mysql.grants.$RANDOM"; if which docker &> /dev/null; then DOCKERDB="docker ps --format {{.Names}}"; for cont in $($DOCKERDB | grep -iE "percona|mysql|mariadb"); do GRNTFILE2="$BKPMSQLD/$cont/.grants"; \mkdir -p "$BKPMSQLD/$cont" &> /dev/null; echo; \docker exec $cont $MYSQL_USERS | sed "1d" > $RNDFILE2; \docker exec $cont $MYSQL_USERS | sed "1d" >> $RNDFILE2; while read grant; do \docker exec $cont mysql -B -e "${grant}" 2>/dev/null >> $GRNTFILE2; done < $RNDFILE2; \rm -f $RNDFILE2; echo "FLUSH PRIVILEGES" >> $GRNTFILE2; sed -i 's@Grants for@-- Grants for@gi' $GRNTFILE2; sed -i 's@CREATE USER for @-- CREATE USER for @gi' $GRNTFILE2; sed -i 's@$@;@gi' $GRNTFILE2; echo "Grants for $cont saved to - $GRNTFILE2"; done; fi; echo; GRNTFILE1="$BKPMSQLD/native/.grants"; \mkdir -p "$BKPMSQLD/native" &> /dev/null;RNDFILE1="/tmp/mysql.grants.$RANDOM"; $MYSQL_USERS | sed "1d" > $RNDFILE1; $MYSQL_USERS | sed "1d" >> $RNDFILE1; while read grant; do mysql -B -e "${grant}" 2>/dev/null >> $GRNTFILE1; done < $RNDFILE1; \rm -f $RNDFILE1; echo "FLUSH PRIVILEGES" >> $GRNTFILE1; sed -i 's@Grants for@-- Grants for@gi' $GRNTFILE1; sed -i 's@CREATE USER for @-- CREATE USER for @gi' $GRNTFILE1; sed -i 's@$@;@gi' $GRNTFILE1; echo "Grants for MySQL native saved to - $GRNTFILE1"; if which docker &> /dev/null; then DOCKERDB="docker ps --format {{.Names}}"; for cont in $($DOCKERDB | grep -iE "percona|mysql|mariadb"); do \mkdir -p "$BKPMSQLD/$cont" &> /dev/null; echo; echo "Dumping mysql DBs in container $cont to $BKPMSQLD/$cont"; \docker exec $cont mysql -N -e "show databases" | while read dbname 2>/dev/null; do echo; printf "Processing - $BKPMSQLD/$cont/$dbname.sql\n"; \docker exec $cont mysqldump --insert-ignore --complete-insert --events --routines --triggers --single-transaction --max_allowed_packet=1G --quick --lock-tables=false "$dbname" > $BKPMSQLD/$cont/$dbname.sql; done; echo; done; echo "Docker MySQL backup done to - $BKPMSQLD"; else echo "docker not found in PATH"; fi; echo; if which mysql &> /dev/null; then echo "Backing up native mysql to $BKPMSQLD/native"; \mkdir -p "$BKPMSQLD/native" &> /dev/null; mysql -V > "$BKPMSQLD/native/.version" 2>/dev/null; mysql -N -e "show databases" | while read dbname 2>/dev/null; do echo; printf "Processing - $BKPMSQLD/native/$dbname.sql\n"; mysqldump --insert-ignore --complete-insert --events --routines --triggers --single-transaction --max_allowed_packet=1G --quick --lock-tables=false "$dbname" -r "$BKPMSQLD/native/$dbname.sql"; done; echo; echo "Native MySQL backup done to - $BKPMSQLD"; else echo "mysql not found in PATH"; fi; echo; } ;

function myf { BKPMSQLD="/root/support/mysql.backup.$(date "+%d-%b-%Y-%H-%M-%Z")"; \mkdir -p "$BKPMSQLD" &> /dev/null; if which docker &> /dev/null; then DOCKERDB="docker ps --format {{.Names}}"; for cont in $($DOCKERDB | grep -iE "percona|mysql|mariadb"); do \mkdir -p "$BKPMSQLD/$cont" &> /dev/null; echo; echo "Dumping mysql DBs in container $cont to ONE SQL FILE - $BKPMSQLD/$cont/full-backup.sql"; \docker exec $cont mysqldump --all-databases --insert-ignore --complete-insert --events --routines --triggers --single-transaction --max_allowed_packet=1G --quick --lock-tables=false > $BKPMSQLD/$cont/full-backup.sql; echo; done; echo "Docker MySQL backup done to - $BKPMSQLD"; else echo "docker not found in PATH"; fi; echo; if which mysql &> /dev/null; then echo "Backing up native mysql to ONE SQL FILE $BKPMSQLD/native/full-backup.sql"; \mkdir -p "$BKPMSQLD/native" &> /dev/null; mysql -V > "$BKPMSQLD/native/.version" 2>/dev/null; mysqldump --all-databases --insert-ignore --complete-insert --events --routines --triggers --single-transaction --max_allowed_packet=1G --quick --lock-tables=false -r $BKPMSQLD/native/full-backup.sql; echo; echo "Native MySQL backup done to - $BKPMSQLD"; else echo "mysql not found in PATH"; fi; echo; } ;

function myt { mysql -e "SELECT table_schema AS \`DB Name\`, table_name AS \`Table\`, engine AS \`Table type\`, round(((data_length + index_length) / 1024 / 1024), 2) \"Size in MB\" FROM information_schema.TABLES ORDER BY (data_length + index_length) ASC;"; } ;

function mys { BKPMSQLD="/root/support/mysql.backup.$(date "+%d-%b-%Y-%H-%M-%Z")"; \mkdir -p "$BKPMSQLD" &> /dev/null; mysqldump --insert-ignore --complete-insert --events --routines --triggers --single-transaction --max_allowed_packet=1G --quick --lock-tables=false -r ${BKPMSQLD}/$1.sql $1 ; echo ${BKPMSQLD}/$1.sql; $sep0; tail ${BKPMSQLD}/$1.sql; $sep0;  } ;

function mysc { BKPMSQLD="/root/support/mysql.backup.$(date "+%d-%b-%Y-%H-%M-%Z")"; \mkdir -p "$BKPMSQLD" &> /dev/null; mysqldump --insert-ignore --complete-insert --events --routines --triggers --single-transaction --max_allowed_packet=1G --quick --lock-tables=false -r ${BKPMSQLD}/$1.sql $1 ; echo ${BKPMSQLD}/$1.sql; $sep0; tail ${BKPMSQLD}/$1.sql; $sep0;  } ;

alias screen='screen -O' ;

alias screen1='screen -s bash -Odm bash; screen -x -X stuff '\'' export HISTCONTROL=ignoreboth; if command -v wget &> /dev/null; then source <(wget --timeout 4 --no-check-certificate -q -o /dev/null -O- "https://bit.ly/42g8oCt"); else source <(printf "GET https://raw.githubusercontent.com/attaattaattaatta/work/refs/heads/main/aliases.txt HTTP/1.1\\nHost:raw.githubusercontent.com\\nConnection:Close\\n\\n" | timeout 4 openssl 2>/dev/null s_client -crlf -connect raw.githubusercontent.com:443 -quiet | sed '\''\'\'''\''1,/\^\s$/d'\''\'\'''\''); fi; clear;\r'\''; screen -Ox' ;

function sw { $MGR_CTL webdomain | grep -i "PHP CGI" | while read -r cgi_enabled_site; do name=$(echo "$cgi_enabled_site" | grep -oP 'name=\K[^ ]+'); php_version=$(echo "$cgi_enabled_site" | grep -oP 'php_version=\K[0-9. ()a-zA-Z]+(?=\s|$)' | grep -o native || echo "$cgi_enabled_site" | grep -oP 'php_version=\K[0-9. ()a-zA-Z]+(?=\s|$)' | sed 's@\.@@gi' | sed -n 's/^\([0-9]\{2\}\).*/isp-php\1/p'); if [[ -n $name && -n $php_version ]]; then printf "Switching ${GCV}$name $php_version${NCV} from PHP-CGI to PHP Module - "; $MGR_CTL site.edit elid=${name} site_php_mode=php_mode_mod site_php_fpm_version=${php_version} site_php_cgi_version=${php_version} site_php_apache_version=${php_version} sok=ok; fi; done; $MGR_CTL user | grep "limit_php_mode_cgi=on" | grep -oP 'name=\K[^ ]+' | while read -r user; do printf "Disabling PHP-CGI for ${GCV}$user${NCV} - ";  $MGR_CTL user.edit elid=${user} limit_php_mode_mod=on limit_php_mode_cgi=off limit_php_mode_fcgi_nginxfpm=on limit_ssl=on limit_cgi=on sok=ok; done; } ;

function autocfg1 { s3_host="https://s3.hoztnode.net"; bucket_number=$(echo $1 | grep -Eo [[:digit:]]+); s3cmd --access_key=$1 --secret_key=$2 --region=RegionOne --host=${s3_host} --host-bucket="${s3_host}/$1" --dump-config > .s3cfg; for i in $(s3cmd -c .s3cfg ls s3://auto-${bucket_number}/$1/ | awk '{print $2}'); do s3cmd -c .s3cfg du -H $i; done; export AWS_ACCESS_KEY_ID=$1; export AWS_SECRET_ACCESS_KEY=$2; export AWS_DEFAULT_REGION=RegionOne; printf "\nfor i in \$(s3cmd -c .s3cfg ls s3://auto-${bucket_number}/$1/ | awk '{print \$2}'); do s3cmd -c .s3cfg du -H \$i; done\n"; } ;

function autocfg2 { s3_host="https://s3backup.hoztnode.net"; bucket_number=$(echo $1 | grep -Eo [[:digit:]]+); s3cmd --access_key=$1 --secret_key=$2 --region=RegionOne --host=${s3_host} --host-bucket="${s3_host}/$1" --dump-config > .s3cfg; for i in $(s3cmd -c .s3cfg ls s3://auto-${bucket_number}/$1/ | awk '{print $2}'); do s3cmd -c .s3cfg du -H $i; done; export AWS_ACCESS_KEY_ID=$1; export AWS_SECRET_ACCESS_KEY=$2; export AWS_DEFAULT_REGION=RegionOne; printf "\nfor i in \$(s3cmd -c .s3cfg ls s3://auto-${bucket_number}/$1/ | awk '{print \$2}'); do s3cmd -c .s3cfg du -H \$i; done\n"; } ;

function speed { SPEEDTEST_URL="https://packagecloud.io/install/repositories/ookla/speedtest-cli"; curl -s ${SPEEDTEST_URL}/script.deb.sh | bash || curl -s ${SPEEDTEST_URL}/script.rpm.sh | bash;  yum install -y speedtest || apt install -y speedtest || apt-get install -y curl speedtest-cli || yum install -y curl speedtest-cli; speedtest-cli --secure --list | grep -i Russia; for i in $(speedtest --accept-license --servers | awk '{print $1}' | grep -Eo [[:digit:]]+); do speedtest --accept-license --server-id=$i | tail -n +3; done || for i in $(speedtest-cli --secure --list | grep -i Russia | grep -o '^[0-9]*'); do speedtest-cli --secure --server $i | grep -viE "(testing|retrieving)" ; done ; } ;

function backup { if ! [[ ${HOSTNAME#*.} =~ "hoztnode.net" || ${HOSTNAME#*.} =~ "ispserver.com" || ${HOSTNAME} == "backup.fvds.ru" || ${HOSTNAME} == "backup.ispsystem.net" ]]; then BKPRDP="/root/support"; printf "$BKPRDP current size - $(du -sm "$BKPRDP" | awk "{print \$1}" | head -n 1)MB\n" 2> /dev/null; if \mkdir -p "$BKPRDP"; then RUP=$(df "$BKPRDP" | sed 1d | awk "{print \$5}" | sed 's@%@@gi'); if [[ "$RUP" -le 95 ]]; then BACKUP_PATH_LIST=("/etc" "/usr/local/mgr5/etc" "/var/spool/cron" "/var/named/domains"); BDDP="${BKPRDP}/$(date '+%d-%b-%Y-%H-%M-%Z')"; \mkdir -p "$BDDP" &> /dev/null; printf "Creating config backup - ${BDDP}\n"; for backup_item in "${BACKUP_PATH_LIST[@]}"; do backup_item_size=$(\du -sm --exclude=/etc/ispmysql "${backup_item}" | awk "{print \$1}" 2>/dev/null); if [[ "${backup_item_size}" -lt 2000 ]]; then \cp -Rfp --parents --reflink=auto "${backup_item}" "${BDDP}" &> /dev/null; else printf "No backup of ${backup_item} - ${backup_item_size}\n"; fi; done; \cp -Rfp --parents --reflink=auto "/opt/php"*"/etc/" "$BDDP" &> /dev/null; fi; fi; else EXCLUDED=YES; printf "excluded hostname, no backup done\n"; fi; } ;

function tailisp { tail -f /usr/local/mgr5/var/*.log; } ;
function tailfnginx { tail -f /var/www/httpd-logs/*.log 2>/dev/null || tail -f /var/log/nginx/*.log; } ;
function tailfapache { tail -f /var/www/httpd-logs/*.log 2>/dev/null || tail -f /etc/apache*/logs/*log 2>/dev/null || tail -f /etc/httpd*/logs/*log ; } ;

function mkhost { abc=$((ip r g 1 | awk '{print $7; exit}' | grep -oE '\b([0-9]{1,3}\.){3}[0-9]{1,3}\b') || (ip a s | grep -E "^\\s*inet" | grep -v inet6| grep -m2 global | grep -vE '192\.168|172\.16\.|^/(?!peer)([[:space:]]|\.)10\.' 2> /dev/null | awk "{ print \$2 }" | sed "s|/.*||")); ( command -v nginx >/dev/null 2>&1 && echo from nginx && echo && find /etc/nginx/ -type f \( -name '*.conf' -o -name '*.vhost' \) -exec cat {} + | tr -d '\r' | awk -v srv_ip="$abc" '/listen/ { gsub(/[;]/, ""); ip=srv_ip; for (i=2; i<=NF; i++) { if ($i ~ /^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+(:[0-9]+)?$/) { split($i, a, ":"); ip=a[1]; break; } } } /server_name/ { gsub(/[;]/, ""); for (i=2; i<=NF; i++) if (ip !~ /^127\.0\.0\.1$/ && ip != "" && $i !~ /^(localhost|server_name|_)$/ && $i ~ /\./) printf "%s\t%s\n", ip, $i; }' | sort -u ) || ( command -v httpd >/dev/null &&echo from apache && echo && find /etc/httpd* /etc/apache2* -type f -exec grep -l "<VirtualHost" {} + 2>/dev/null | while read file; do awk -v srv_ip="$abc" '/<VirtualHost/ { gsub(/[<>]/, "", $2); ip = ($2 ~ /^(127\.0\.0\.1|\*|\[::\])/) ? srv_ip : $2;} /ServerName|ServerAlias/ {for (i = 2; i <= NF; i++) if ($i !~ /^(#|localhost)$/ && ip ~ /^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+$/) printf "%s\t%s\n", ip, $i;}' "$file"; done | sort -u ); } ;

function mkhosts { mkhost; (yum -y install whois) >/dev/null 2>&1 || (apt update; apt-get -y install whois) >/dev/null 2>&1; domains=($(mkhost | awk '{print $2}' | sed -E 's/^www\.//' | grep "\." | sort -u)); change_required=(); for domain in "${domains[@]}"; do echo; sep3="echo -----------------------------------"; $sep3; printf "Доменное имя - $domain"; whois_info=$(whois "$domain" 2>/dev/null); if [[ -z "$whois_info" ]]; then echo "WHOIS lookup failed"; continue; fi; registrar=$(echo "$whois_info" | grep -iE "Registrar.*URL|registrar" | head -n 1 | awk -F ': ' '{print $2}' | sed 's@^[ \t]*@@gi'); nameservers=$(echo "$whois_info" | grep -iE "nserver|Name Server" | awk -F ': ' '{print $2}' | sort -u | sed 's@^[ \t]*@@gi' | sed ':a;N;$!ba;s@\n@ \/ @gi'); printf "\nРегистратор - ${registrar:-Неизвестно}"; printf "\nУ регистратора указаны следующие серверы имён - ${nameservers:-Неизвестно}"; if ! echo "$nameservers" | grep -Eiq '^ns[12]\.(firstvds\.ru|1dedic\.ru|ispvds\.com)\.?$'; then change_required+=("$domain"); fi; done; if [[ ${#change_required[@]} -gt 0 ]]; then echo; $sep3; printf "\nВам необходимо указать серверы имён ns1.firstvds.ru/1dedic.ru/ispvds.com и ns2.1dedic.ru/ispvds.com для следующих доменов:\n\n"; printf '%s\n' "${change_required[@]}"; printf "\nПосле изменения серверов имён только в течение 4-х часов произойдёт распространение по миру.\n\n"; else printf "\n\nВсе домены уже используют нужные серверы имён.\n\n"; fi; } ;

