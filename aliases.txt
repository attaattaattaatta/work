MGR_PATH="/usr/local/mgr5" ;
MGR_BIN="$MGR_PATH/sbin/mgrctl" ; 
MGR_CTL="$MGR_PATH/sbin/mgrctl -m ispmgr" ; 
MGR_MAIN_CONF_FILE="$MGR_PATH/etc/ispmgr.conf" ; 

GCV="\033[0;92m" ; 
LRV="\033[1;91m" ; 
YCV="\033[01;33m" ; 
NCV="\033[0m" ; 

alias ispmgrctl="$MGR_CTL" ; 

function fix7 { sed -i "s/^mirrorlist=/#mirrorlist=/g" /etc/yum.repos.d/CentOS-*; sed -i "s|#baseurl=http://mirror.centos.org|baseurl=http://vault.centos.org|g" /etc/yum.repos.d/CentOS-*; yum --enablerepo=updates clean metadata > /dev/null 2>&1; \rm -f /etc/yum.repos.d/epel-testing.repo /etc/yum.repos.d/epel.repo > /dev/null 2>&1; } ;

function net1 { if command -v netstat &> /dev/null; then netstat -nt | awk "{print \$6}" | sort | uniq -c | sort -n -k 1 -r | head -n -1; else ss -tulpan "! dst 0.0.0.0 and ! dst [::1]" | awk " \$6 ~ /^[0-9]/ {print \$6}" | cut -d: -f1 | sort | uniq -c | sort -n | tail -n 6; ss -nta | awk "{print \$1}" | sort | uniq -c | sort -n -k 1 -r | head -n -1; fi; } ;

function net2 { while true; do lsof -i -n -P | grep -vE "LISTEN|rpcbind|ESTABLISHED|named|chronyd|memcached|ntpd|core|COMMAND"; sleep 1s; done; } ;

function net3 { if command -v netstat &> /dev/null; then netstat -ntu | awk " \$5 ~ /^[0-9]/ {print \$5}" | cut -d: -f1 | sort | uniq -c | sort -n | tail -n 300; else ss -tulpan "! dst 0.0.0.0 and ! dst [::1]" | awk " \$6 ~ /^[0-9]/ {print \$6}" | cut -d: -f1 | sort | uniq -c | sort -n | tail -n 300; fi; } ;

function net4 { watch -n 2 "ss -s && echo &&  cat /proc/net/sockstat && echo && netstat -nt | awk \"{print \$6}\" | sort | uniq -c | sort -n -k 1 -r | head -n -1"; } ;

function tuner { yum install -y perl-diagnostics >dev/null 2>&1; mysql -V; grep -RiE "socket\s+?=" /etc/my*; mysql -e ' show variables where Variable_Name in ("innodb_lru_scan_depth", "optimizer_search_depth", "myisam_recover", "myisam_recover", "max_connect_errors", "default_storage_engine", "transaction_isolation", "tx_isolation", "slave_net_timeout", "innodb_use_sys_malloc", "sql_mode", "collation_server", "init_connect", "character_set_server", "query_cache_size", "query_cache_limit", "query_cache_type", "expire_logs_days", "max_binlog_size", "thread_stack", "thread_pool_size", "open_files_limit", "table_cache", "table_definition_cache", "table_open_cache", "key_buffer_size", "sort_buffer_size", "join_buffer_size", "innodb_force_recovery ", "innodb_buffer_pool_size", "innodb_io_capacity_max", "innodb_io_capacity", "innodb_strict_mode", "innodb_max_dirty_pages_pct", "innodb_thread_concurrency", "innodb_print_all_deadlocks", "innodb_buffer_pool_instances", "innodb_log_file_size", "innodb_log_buffer_size", "innodb_file_format", "innodb_flush_log_at_trx_commit", "innodb_flush_method", "innodb_file_per_table", "wait_timeout", "interactive_timeout", "back_log", "threads_connected", "thread_concurrency", "thread_cache_size", "max_connections", "max_heap_table_size", "tmp_table_size", "max_allowed_packet", "symbolic_links", "local_infile", "bind_address", "basedir", "datadir", "tmpdir", "log_warnings", "long_query_time", "slow_query_log", "slow_query_log_file", "log_error", "pid_file", "socket", "binlog_expire_logs_seconds","innodb_page_cleaners")'; mysql -e "SELECT @@character_set_database, @@collation_database;"; perl <($wgtvr  "https://raw.github.com/major/MySQLTuner-perl/master/mysqltuner.pl") --buffers --skippassword --user root --host localhost; } ;

function nr { nginx -T | grep root $1 || grep -RiIn root /etc/nginx/* $1 ; } ;

function nacc { nginx -T | grep acc $1 || grep -RiIn acc /etc/nginx/* $1 ; } ;

function nerr { nginx -T | grep err $1 || grep -RiIn err /etc/nginx/* $1 ; } ;

function nssl { nginx -T | grep ssl_ $1 || grep -RiIn ssl_ /etc/nginx/* $1 ; } ;

function nconf { nginx -T | grep conf $1 || grep -RiIn conf /etc/nginx/* $1 ; } ;

function nserv { nginx -T | grep server_name $1 || grep -RiIn server_name /etc/nginx/* $1 ; } ;

function ninc { nginx -T | grep include $1 || grep -RiIn include /etc/nginx/* $1 ; } ;

alias rsynca='rsync -azxl --no-i-r --info=progress2' ;

alias rsynch='rsync -alHzx --no-i-r --info=progress2' ;

alias grepn='grep -RiIn' ;

alias grepl='grep -RiIl' ;

function sysfailed { systemctl list-units --failed; } ;

alias ll='ls -la' ;

alias la='ls -la' ;

alias du='du -sch' ;

function cl { cat /etc/crontab; for user in $(getent passwd | cut -f1 -d: ); do echo $user && echo && crontab -u $user -l && echo; done; systemctl list-timers; } ;

alias lat='ls -latrh' ;

alias lah='ls -latrh' ;

function sysfail { systemctl list-units --state=failed; } ;

alias journalctl='journalctl -l --no-pager -n 200 -u'; 

function exit1 {  kill -9 $$; } ;

function exit2 {  history -c; > /root/.bash_history; kill -9 $$; } ;

function tw {  bash <($wgtvr https://bit.ly/3nelivO) tweak; } ;

function mylog { grep -ri "log.error" /etc/my*; } ;

function myl { DBSZ="SELECT table_schema AS \`DB Name\`, ROUND(SUM(data_length + index_length) / 1024 / 1024, 1) AS \`DB Size(MB)\` FROM information_schema.tables GROUP BY table_schema ORDER BY \`DB Size(MB)\` ASC;"; if which docker &> /dev/null; then DOCKERDB="docker ps --format {{.Names}}"; for cont in $($DOCKERDB | grep -iE "percona|mysql|mariadb"); do echo; printf "DBs in container ${cont}:\n\n"; \docker exec -it $cont mysql -e "$DBSZ" 2>/dev/null; done; fi; echo; printf "Native mysql:\n\n"; mysql -e "$DBSZ" 2>/dev/null; } ;

function myf { BKPMSQLD="/root/support/mysql.backup.$(date "+%d-%b-%Y-%H-%M-%Z")"; \mkdir -p "$BKPMSQLD" &> /dev/null; if which docker &> /dev/null; then DOCKERDB="docker ps --format {{.Names}}"; for cont in $($DOCKERDB | grep -iE "percona|mysql|mariadb"); do \mkdir -p "$BKPMSQLD/$cont" &> /dev/null; echo; echo "Dumping mysql DBs in container $cont to ONE SQL FILE - $BKPMSQLD/$cont/full-backup.sql"; \docker exec $cont mysqldump --all-databases --insert-ignore --complete-insert --events --routines --triggers --single-transaction --max_allowed_packet=1G --quick --lock-tables=false > $BKPMSQLD/$cont/full-backup.sql; echo; done; echo "Docker MySQL backup done to - $BKPMSQLD"; else echo "docker not found in PATH"; fi; echo; if which mysql &> /dev/null; then echo "Backing up native mysql to ONE SQL FILE $BKPMSQLD/native/full-backup.sql"; \mkdir -p "$BKPMSQLD/native" &> /dev/null; mysql -V > "$BKPMSQLD/native/.version" 2>/dev/null; mysqldump --all-databases --insert-ignore --complete-insert --events --routines --triggers --single-transaction --max_allowed_packet=1G --quick --lock-tables=false -r $BKPMSQLD/native/full-backup.sql; echo; echo "Native MySQL backup done to - $BKPMSQLD"; else echo "mysql not found in PATH"; fi; echo; } ;

function myt { mysql -e "SELECT table_schema AS \`DB Name\`, table_name AS \`Table\`, engine AS \`Table type\`, round(((data_length + index_length) / 1024 / 1024), 2) \"Size in MB\" FROM information_schema.TABLES ORDER BY (data_length + index_length) ASC;"; } ;

function myg { BKPMSQLD="/root/support/mysql.backup.$(date "+%d-%b-%Y-%H-%M-%Z")"; \mkdir -p "$BKPMSQLD" &> /dev/null; RNDFILE2="/tmp/mysql.grants.$RANDOM"; if which docker &> /dev/null; then DOCKERDB="docker ps --format {{.Names}}"; for cont in $($DOCKERDB | grep -iE "percona|mysql|mariadb"); do GRNTFILE2="$BKPMSQLD/$cont/.grants"; \mkdir -p "$BKPMSQLD/$cont" &> /dev/null; echo; \docker exec $cont \mysql -e "select concat('show create user ','\'',user,'\'@\'',host,'\'',';') from mysql.user" | sed "1d" > $RNDFILE2; \docker exec $cont \mysql -e "select concat('show grants for ','\'',user,'\'@\'',host,'\'',';') from mysql.user" | sed "1d" >> $RNDFILE2; while read grant; do \docker exec $cont \mysql -B -e "${grant}" 2>/dev/null >> $GRNTFILE2; done < $RNDFILE2; \rm -f $RNDFILE2; echo "FLUSH PRIVILEGES" >> $GRNTFILE2; sed -i 's@Grants for@-- Grants for@gi' $GRNTFILE2; sed -i 's@CREATE USER for @-- CREATE USER for @gi' $GRNTFILE2; sed -i 's@$@;@gi' $GRNTFILE2; echo "Grants for $cont saved to - $GRNTFILE2"; done; fi; echo; GRNTFILE1="$BKPMSQLD/native/.grants"; \mkdir -p "$BKPMSQLD/native" &> /dev/null;RNDFILE1="/tmp/mysql.grants.$RANDOM"; \mysql -e "select concat('show create user ','\'',user,'\'@\'',host,'\'',';') from mysql.user" | sed "1d" > $RNDFILE1; \mysql -e "select concat('show grants for ','\'',user,'\'@\'',host,'\'',';') from mysql.user" | sed "1d" >> $RNDFILE1; while read grant; do \mysql -B -e "${grant}" 2>/dev/null >> $GRNTFILE1; done < $RNDFILE1; \rm -f $RNDFILE1; echo "FLUSH PRIVILEGES" >> $GRNTFILE1; sed -i 's@Grants for@-- Grants for@gi' $GRNTFILE1; sed -i 's@CREATE USER for @-- CREATE USER for @gi' $GRNTFILE1; sed -i 's@$@;@gi' $GRNTFILE1; echo "Grants for MySQL native saved to - $GRNTFILE1"; } ;

function myb { BKPMSQLD="/root/support/mysql.backup.$(date "+%d-%b-%Y-%H-%M-%Z")"; myg; \mkdir -p "$BKPMSQLD" &> /dev/null; if which docker &> /dev/null; then DOCKERDB="docker ps --format {{.Names}}"; for cont in $($DOCKERDB | grep -iE "percona|mysql|mariadb"); do \mkdir -p "$BKPMSQLD/$cont" &> /dev/null; echo; echo "Dumping mysql DBs in container $cont to $BKPMSQLD/$cont"; \docker exec $cont mysql -N -e "show databases" | while read dbname 2>/dev/null; do echo; printf "Processing - $BKPMSQLD/$cont/$dbname.sql\n"; \docker exec $cont mysqldump --insert-ignore --complete-insert --events --routines --triggers --single-transaction --max_allowed_packet=1G --quick --lock-tables=false "$dbname" > $BKPMSQLD/$cont/$dbname.sql; done; echo; done; echo "Docker MySQL backup done to - $BKPMSQLD"; else echo "docker not found in PATH"; fi; echo; if which mysql &> /dev/null; then echo "Backing up native mysql to $BKPMSQLD/native"; \mkdir -p "$BKPMSQLD/native" &> /dev/null; mysql -V > "$BKPMSQLD/native/.version" 2>/dev/null; mysql -N -e "show databases" | while read dbname 2>/dev/null; do echo; printf "Processing - $BKPMSQLD/native/$dbname.sql\n"; mysqldump --insert-ignore --complete-insert --events --routines --triggers --single-transaction --max_allowed_packet=1G --quick --lock-tables=false "$dbname" -r "$BKPMSQLD/native/$dbname.sql"; done; echo; echo "Native MySQL backup done to - $BKPMSQLD"; else echo "mysql not found in PATH"; fi; echo; } ;

function mys { BKPMSQLD="/root/support/mysql.backup.$(date "+%d-%b-%Y-%H-%M-%Z")"; \mkdir -p "$BKPMSQLD" &> /dev/null; mysqldump --insert-ignore --complete-insert --events --routines --triggers --single-transaction --max_allowed_packet=1G --quick --lock-tables=false -r ${BKPMSQLD}/$1.sql $1 ; echo ${BKPMSQLD}/$1.sql; $sep0; tail ${BKPMSQLD}/$1.sql; $sep0;  } ;

function mysc { BKPMSQLD="/root/support/mysql.backup.$(date "+%d-%b-%Y-%H-%M-%Z")"; \mkdir -p "$BKPMSQLD" &> /dev/null; mysqldump --insert-ignore --complete-insert --events --routines --triggers --single-transaction --max_allowed_packet=1G --quick --lock-tables=false -r ${BKPMSQLD}/$1.sql $1 ; echo ${BKPMSQLD}/$1.sql; $sep0; tail ${BKPMSQLD}/$1.sql; $sep0;  } ;

alias screen='screen -O' ;

alias screen1='screen -s bash -Odm bash; screen -x -X stuff '\'' export HISTCONTROL=ignoreboth; if command -v wget &> /dev/null; then source <(wget --timeout 4 --no-check-certificate -q -o /dev/null -O- "https://bit.ly/42g8oCt"); else source <(printf "GET https://raw.githubusercontent.com/attaattaattaatta/work/refs/heads/main/aliases.txt HTTP/1.1\\nHost:raw.githubusercontent.com\\nConnection:Close\\n\\n" | timeout 4 openssl 2>/dev/null s_client -crlf -connect raw.githubusercontent.com:443 -quiet | sed '\''\'\'''\''1,/\^\s$/d'\''\'\'''\''); fi; clear;\r'\''; screen -Ox' ;

function autocfg1 { s3_host="https://s3.hoztnode.net"; bucket_number=$(echo $1 | grep -Eo [[:digit:]]+); s3cmd --access_key=$1 --secret_key=$2 --region=RegionOne --host=${s3_host} --host-bucket="${s3_host}/$1" --dump-config > .s3cfg; for i in $(s3cmd -c .s3cfg ls s3://auto-${bucket_number}/$1/ | awk '{print $2}'); do s3cmd -c .s3cfg du -H $i; done; export AWS_ACCESS_KEY_ID=$1; export AWS_SECRET_ACCESS_KEY=$2; export AWS_DEFAULT_REGION=RegionOne; export S3_ENDPOINT_URL="https://s3.hoztnode.net"; printf "\n${s3_host}"; printf "\nfor i in \$(s3cmd -c .s3cfg ls s3://auto-${bucket_number}/ | awk '{print \$2}'); do s3cmd -c .s3cfg du -H \$i; done\n"; printf "\ns3cmd --no-check-certificate --skip-existing --no-check-md5 --no-progress -c .s3cfg sync s3://auto-${bucket_number}/ full/\n"; printf "\ns5cmd cp s3://auto-${bucket_number}/auto_${bucket_number}/2023-04-09/* /var/www/data/13030793/\n"; } ;

function autocfg2 { s3_host="https://s3backup.hoztnode.net"; bucket_number=$(echo $1 | grep -Eo [[:digit:]]+); s3cmd --access_key=$1 --secret_key=$2 --region=RegionOne --host=${s3_host} --host-bucket="${s3_host}/$1" --dump-config > .s3cfg; for i in $(s3cmd -c .s3cfg ls s3://auto-${bucket_number}/$1/ | awk '{print $2}'); do s3cmd -c .s3cfg du -H $i; done; export AWS_ACCESS_KEY_ID=$1; export AWS_SECRET_ACCESS_KEY=$2; export AWS_DEFAULT_REGION=RegionOne; export S3_ENDPOINT_URL="https://s3backup.hoztnode.net"; printf "\n${s3_host}"; printf "\nfor i in \$(s3cmd -c .s3cfg ls s3://auto-${bucket_number}/ | awk '{print \$2}'); do s3cmd -c .s3cfg du -H \$i; done\n"; printf "\ns3cmd --no-check-certificate --skip-existing --no-check-md5 --no-progress -c .s3cfg sync s3://auto-${bucket_number}/ full/\n"; printf "\ns5cmd cp s3://auto-${bucket_number}/auto_${bucket_number}/2023-04-09/* /var/www/data/13030793/\n"; } ;

function speed { SPEEDTEST_URL="https://packagecloud.io/install/repositories/ookla/speedtest-cli"; command -v speedtest &>/dev/null || { command -v apt &>/dev/null && { curl -s ${SPEEDTEST_URL}/script.deb.sh | bash &>/dev/null && apt install -y speedtest &>/dev/null || apt-get install -y curl speedtest-cli &>/dev/null; } || command -v yum &>/dev/null && { curl -s ${SPEEDTEST_URL}/script.rpm.sh | bash &>/dev/null && yum install -y speedtest &>/dev/null; } || { echo "Error installing speedtest"; }; }; SERVERS=$(speedtest --accept-license --servers 2>/dev/null | awk '{print $1}' | grep -Eo '[0-9]+'); [[ -z "$SERVERS" ]] && SERVERS=$(speedtest-cli --secure --list | grep -i Russia | grep -o '^[0-9]*'); [[ -z "$SERVERS" ]] && return 1; for SERVER in $SERVERS; do command -v speedtest &>/dev/null && { speedtest-cli --secure --server $SERVER | grep -viE "(testing|retrieving)" 2>/dev/null || speedtest --accept-license --server-id=$SERVER | tail -n +3 2>/dev/null; }; done; } ;

function backup { if ! [[ ${HOSTNAME#*.} =~ "hoztnode.net" || ${HOSTNAME#*.} =~ "ispserver.com" || ${HOSTNAME} == "backup.fvds.ru" || ${HOSTNAME} == "backup.ispsystem.net" ]]; then BKPRDP="/root/support"; printf "$BKPRDP current size - $(du -sm "$BKPRDP" | awk '{print $1}' | head -n 1)MB\n" 2>/dev/null; if \mkdir -p "$BKPRDP"; then RUP=$(df "$BKPRDP" | sed 1d | awk '{print $5}' | sed 's@%@@gi'); if [[ "$RUP" -le 95 ]]; then BACKUP_PATH_LIST=("/etc" "/usr/local/mgr5/etc" "/var/spool/cron" "/var/named/domains"); BDDP="${BKPRDP}/$(date '+%d-%b-%Y-%H-%M-%Z')"; \mkdir -p "$BDDP" &> /dev/null; printf "Creating config backup - ${BDDP}\n"; for backup_item in "${BACKUP_PATH_LIST[@]}"; do backup_item_size=$(\du -sm --exclude=/etc/ispmysql "${backup_item}" 2>/dev/null | awk '{print $1}'); if [[ "${backup_item_size}" -lt 2000 ]]; then \cp -Rfp --parents --reflink=auto "${backup_item}" "${BDDP}" &> /dev/null && chmod --reference="${backup_item}" "${BDDP}${backup_item}" 2>/dev/null; else printf "No backup of ${backup_item} - ${backup_item_size}\n"; fi; done; \cp -Rfp --parents --reflink=auto "/opt/php"*"/etc/" "$BDDP" &> /dev/null; for dir in /opt /usr /var; do [[ -d "$dir" && -d "${BDDP}${dir}" ]] && chmod --reference="$dir" "${BDDP}${dir}" 2>/dev/null; done; fi; fi; else EXCLUDED=YES; printf "excluded hostname, no backup done\n"; fi; }

function tailisp { tail -f /usr/local/mgr5/var/*.log; } ;
function tailnacc { tail -f /var/www/httpd-logs/*acc*.log /var/log/nginx/*acc*.log 2>/dev/null; } ;
function tailnerr { tail -f /var/www/httpd-logs/*err*.log /var/log/nginx/*err*.log 2>/dev/null; } ;
function tailaacc { tail -f /etc/apache*/logs/*cust* /etc/httpd*/logs/*cust* 2>/dev/null; } ;
function tailaerr { tail -f /etc/apache*/logs/*err* /var/log/apache*/error.log /etc/httpd*/logs/*err* /var/log/httpd*/error.log 2>/dev/null; } ;
function iplh { last_hour=$(date -d "1 hour ago" +"%d/%b/%Y:%H"); grep -RIi "$last_hour" /var/www/httpd-logs/*acc*.log /var/log/nginx/*acc*.log 2>/dev/null | awk '{print $1}' | sort | uniq -c | sort -nr | head -200; } ;
function ualh { last_hour=$(date -d "1 hour ago" +"%d/%b/%Y:%H"); grep -RIi "$last_hour" /var/www/httpd-logs/*acc*.log /var/log/nginx/*acc*.log 2>/dev/null | awk '{print $12" "$13" "$14" "$15" "$16" "$17" "$18}' | sort | uniq -c | sort -nr | head -200; } ;

function mkhost { abc=$(ip a s | grep -E "^\\s*inet" | grep -v inet6| grep -m2 global | grep -vE '192\.168|172\.16\.|^/(?!peer)([[:space:]]|\.)10\.' 2> /dev/null | awk "{ print \$2 }" | sed "s|/.*||"); ( command -v nginx >/dev/null 2>&1 && echo from nginx && echo && find /etc/nginx/ -type f \( -name '*.conf' -o -name '*.vhost' \) -exec cat {} + | tr -d '\r' | awk -v srv_ip="$abc" '/listen/ { gsub(/[;]/, ""); ip=srv_ip; for (i=2; i<=NF; i++) { if ($i ~ /^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+(:[0-9]+)?$/) { split($i, a, ":"); ip=a[1]; break; } } } /server_name/ { gsub(/[;]/, ""); for (i=2; i<=NF; i++) if (ip !~ /^127\.0\.0\.1$/ && ip != "" && $i !~ /^(localhost|server_name|_)$/ && $i ~ /\./) printf "%s\t%s\n", ip, $i; }' | sort -u ) || ( (command -v httpd >/dev/null || command -v apache2 >/dev/null) && echo from apache && echo && find /etc/httpd* /etc/apache2* -iname "*.conf" -type f -exec grep -l "<VirtualHost" {} + 2>/dev/null | while read file; do awk -v srv_ip="$abc" '/<VirtualHost/ { gsub(/[<>]/, "", $2); sub(/:[0-9]+$/, "", $2); ip = ($2 ~ /^(127\.0\.0\.1|\*|\[::\])/) ? srv_ip : $2; next } /ServerName|ServerAlias/ { for (i = 2; i <= NF; i++) if ($i ~ /\./ && $i !~ /example\.com/ && $i !~ /\.$/) print ip, $i }' "$file"; done | sort -u ); } ;

function mkhosts { func_v="v1.0.2"; printf "\n%s - %s\n" "${FUNCNAME[0]}" "$func_v"; mkhost; command -v whois >/dev/null 2>&1 || (yum -y install whois >/dev/null 2>&1 || (apt update -y >/dev/null 2>&1 && apt-get -y install whois >/dev/null 2>&1)); command -v idn2 >/dev/null 2>&1 || (yum -y install idn2 >/dev/null 2>&1 || (apt update -y >/dev/null 2>&1 && apt-get -y install idn2 >/dev/null 2>&1));  domains=($(mkhost | awk '{print $2}' | sed -E 's/^www\.//' | grep "\." | sort -u)); change_required=(); for domain in "${domains[@]}"; do echo; sep3="echo -----------------------------------"; $sep3; if [[ "$domain" =~ ^xn-- ]]; then readable_domain=$(idn2 -d "$domain"); printf "Доменное имя - %s (%s)" "$domain" "$readable_domain"; else printf "Доменное имя - $domain"; fi; whois_info=$(whois "$domain" 2>/dev/null); if [[ -z "$whois_info" ]]; then printf "\n${LRV}WHOIS lookup failed${NCV}"; continue; fi; registrar=$(echo "$whois_info" | grep -iE "Registrar.*URL|registrar" | head -n 1 | awk -F ': ' '{print $2}' | sed 's@^[ \t]*@@gi'); nameservers=$(echo "$whois_info" | grep -iE "nserver|Name Server" | awk -F ': ' '{print $2}' | sort -u | sed 's@^[ \t]*@@gi' | sed ':a;N;$!ba;s@\n@ \/ @gi'); printf "\nРегистратор - ${registrar:-Неизвестно}"; printf "\nУ регистратора указаны следующие серверы имён - ${nameservers:-Неизвестно}"; if ! echo "$nameservers" | grep -Eiq '^ns[12]\.(firstvds\.ru|1dedic\.ru|ispvds\.com)\.?$'; then change_required+=("$domain"); fi; done; if [[ ${#change_required[@]} -gt 0 ]]; then echo; $sep3; printf "\nВам необходимо указать серверы имён ns1.firstvds.ru/1dedic.ru/ispvds.com и ns2. для следующих доменов:\n\n"; printf '%s\n' "${change_required[@]}"; printf "\nПосле изменения серверов имён только в течение 4-х часов произойдёт распространение по миру.\n\n"; else printf "\n\nИли пусто или все домены уже используют нужные серверы имён.\n\n"; fi; } ;

function findreplace { echo -e "findreplace - v1.0.9\n"; [[ -z "$1" || -z "$2" ]] && { echo "findreplace <search> <replace> [file|dir]"; return 1; }; [[ -n "$3" && ! -e "$3" ]] && { echo "Error: '$3' does not exist"; return 1; }; target="${3:-$(pwd)}"; type=$( [[ -f "$3" ]] && echo "file" || echo "dir" ); read -p "Replace '$1' with '$2' in $type '$target'? [Y/n] " -n 1 -r; echo; [[ ! $REPLY =~ ^[Yy]$ ]] && echo "Cancelled" && return 1; [[ -f "$3" ]] && sed -i "s@$1@$2@gi" "$3" && echo "Don Don" || { grep -RiIl "$1" "$target" 2>/dev/null | xargs -r sed -i "s@$1@$2@gi"; find "$target" -depth -name "*$1*" -exec bash -c 'mv "$0" "${0//'"$1"'/'"$2"'}"' {} \; echo "Don Don"; } || echo "Not don don"; }

function ssd { ( > smartctl.txt; for d in $(lsblk -e1,7 -d -n -p -o KNAME); do echo $d >> smartctl.txt; echo >> smartctl.txt; export LC_ALL=C; smartctl -a $d >> smartctl.txt; done; cat smartctl.txt;) || (> smartctl.txt; for d in $(lsblk -e1,7 -d -n -o KNAME | grep -v loop | sed 's@^@/dev/@gi'); do echo $d >> smartctl.txt; echo >> smartctl.txt; export LC_ALL=C; smartctl -a $d >> smartctl.txt; done; cat smartctl.txt) } ; 













function aliases { func_and_aliases_after=$(alias | awk -F= '{print $1}' | awk '{print $2}' && declare -F | awk '{print $3}'); comm -13 <(echo "$func_and_aliases_before" | sort) <(echo "$func_and_aliases_after" | sort); } ;
